---
sidebar_label: Mistral
---

import CodeBlock from "@theme/CodeBlock";
import ExampleMistral from "@examples/mistral-completion-example/mistral_completion_example.go";

# Mistral
The Mistral Platform (https://mistral.ai) offers a spectrum of models with different levels of power suitable for different tasks.

This example goes over how to use LangChain to interact with Mistral models, with an example that shows how to get a streaming and non-streaming completion from the Mistral API using the Langchain Go wrapper.

## Configuring the API key
There are two options to set the the Mistral Platform API key.

1. We can do this by setting the environment variable `MISTRAL_API_KEY` to the api key.

2. Or we can do it when initializing the wrapper along with other arguments.
   ```go
    model, err := mistral.New(mistral.WithAPIKey(apiKey))
   ```

## Setting the model name
As mentioned above, there are many models available on the Mistral platform. We can set the model name when initializing the wrapper, and it can be overridden when performing completions through `langchaingo`.
```go
    model, err := mistral.New(mistral.WithAPIKey(apiKey), mistral.WithModel("mistral-small-latest"))
```
  * Currently-listed models on Mistral.ai:
  * `open-mistral-7b` (aka mistral-tiny-2312)
  * `open-mixtral-8x7b` (aka mistral-small-2312): `Note:` DOES NOT seem usable via the mistral-go client library at the moment.
  * `mistral-small-latest` (aka mistral-small-2402)
  * `mistral-medium-latest` (aka mistral-medium-2312)
  * `mistral-large-latest` (aka mistral-large-2402)

<CodeBlock language="go">{ExampleMistral}</CodeBlock>